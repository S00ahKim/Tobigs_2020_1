{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Multiclass SVM 을 직접 구현\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "1.\n",
    "위에서 언급 되었던 **Multiclass SVM** 을 직접 구현하시는 것입니다.  \n",
    "기본적으로 사이킷 런에 있는 SVM 은 멀티클래스 SVM 을 지원합니다.  \n",
    "그러나 과제에서는 그것을 쓰면 안됩니다!  \n",
    "아이리스 데이터는 총 세 개의 클래스가 있으므로 **이 클래스를 one hot 인코딩** 한 뒤,   \n",
    "각각 **binary SVM 을 트레이닝**하고 이 **결과를 조합**하여 multiclass SVM 을 구현하는 것입니다.  \n",
    "\n",
    "2.\n",
    "위에서 말했듯 기본적으로 **one vs one, one vs rest** 방법이 있으며 어떤 것을 구현하든 자유입니다.   \n",
    "만약 투표결과 동점이 나온경우 예를 들어 각각의 SVM 의 결과가 A vs B C 의 경우 A 로 판별 , B vs A C 의 결과 B 로 판별 , C vs A B 의 경우 C 로 판별한 경우  \n",
    "투표를 통해 class 를 결정할 수 없는 경우 **decision_function** 을 활용하시거나,   \n",
    "**가장 개수가 많은 클래스를 사용**하시거나 **랜덤**으로 하나를 뽑거나 하는 방법 등을 이용해 동점자인 경우를 판별해주시면 됩니다.  \n",
    "공식 문서를 보면 사이킷런이 어떤 방법으로 구현했는지가 글로 나와 있으므로 참조하셔도 무관합니다.  \n",
    "\n",
    "3.\n",
    "과제코드에는 제가 iris 데이터를 로드하고 iris 데이터를 one hot 인코딩 한 부분까지 구현해 놓았습니다  \n",
    "또한 decision function 을 호출해서 사용하는 예시도 하나 넣어 놓았으니 참고하시면 됩니다  \n",
    "개인적으로 one vs rest 가 더 구현하기 쉬울것으로 생각되며, 모르는 부분은 언제든 질문해주세요!   \n",
    "생각보다 코드가 길지 않고 어렵지 않습니다.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris =  sns.load_dataset('iris') #data load\n",
    "X = iris.iloc[:,:4]\n",
    "y = iris.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target의 분포 동일하다.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_rest_svm(kernel, gamma, C, X, y):\n",
    "    # One Versus Rest (각각의 model training)\n",
    "    svm_setosa     = SVC(kernel =kernel, gamma = gamma, C = C)\n",
    "    svm_versicolor = SVC(kernel =kernel, gamma = gamma, C = C)\n",
    "    svm_virginica  = SVC(kernel =kernel, gamma = gamma, C = C)\n",
    "    \n",
    "    # train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "    \n",
    "    # 각 클래스 별 모델을 학습시키기 위하여 target을 one-hot encoding 해준다.\n",
    "    y_train_encoded = pd.get_dummies(y_train) \n",
    "    \n",
    "    # 각각의 model training\n",
    "    svm_setosa.fit(X_train,y_train_encoded.iloc[:,0])\n",
    "    svm_versicolor.fit(X_train,y_train_encoded.iloc[:,1])\n",
    "    svm_virginica.fit(X_train,y_train_encoded.iloc[:,2])\n",
    "    \n",
    "    setosa_distance = svm_setosa.decision_function(X_test)\n",
    "    versicolor_distance = svm_versicolor.decision_function(X_test)\n",
    "    virginica_distance = svm_virginica.decision_function(X_test)\n",
    "    \n",
    "    # test 데이터 최종 예측\n",
    "    pred = np.argmax(np.array([setosa_distance, versicolor_distance, virginica_distance]), axis=0)\n",
    "    pred_eng = pd.Series(pred).replace({0:'setosa', 1:'versicolor', 2:'virginica'})\n",
    "    \n",
    "    return accuracy_score(y_test, pred_eng)\n",
    "\n",
    "\n",
    "# 데이터 예측 방식에 대한 주석\n",
    "# * ([svm_setosa가 예측한 결과, svm_versicolor가 예측한 결과, svm_virginica가 예측한 결과]) 순서로 표기\n",
    "# 1. [0, 0, 0]으로 예측 -> decision_function 모두 음수 -> 그나마 큰 값으로 예측하자\n",
    "# 2. [1, 0, 0], [0, 1, 0], [0, 0, 1]으로 예측 -> 하나만 decision_function 양수, 나머지 2개는 음수 -> 큰 값으로 예측\n",
    "# 3. [1, 1, 0], [1, 0, 1], [0, 1, 1]으로 예측 -> 두 개는 decision_function 양수, 하나는 음수 -> 큰 값으로 예측 (거리 클수록 확실한 예측이라 판단)\n",
    "# 4. [1, 1, 1]으로 예측 -> decision_function 모두 양수 -> 거리 가장 큰 값으로 예측\n",
    "# -> 즉, 그냥 단순하게 decision_function의 값이 가장 크게 나온 것으로 예측하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tunning(kernel, gamma_list, C_list, X, y):\n",
    "    score_dict = {} \n",
    "    for gamma in tqdm(gamma_list):\n",
    "        for C in C_list:\n",
    "            score = one_rest_svm(kernel, gamma, C, X, y)\n",
    "            param = '_'.join([kernel, str(gamma), str(C)])\n",
    "            score_dict[param] = score\n",
    "            \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. scaling 하기 전의 데이터로 training\n",
    "X = iris.iloc[:,:4]\n",
    "y = iris.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "kernel = 'rbf'\n",
    "gamma_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "C_list = [0.01, 0.1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 150, 200]\n",
    "\n",
    "# 여러가지 hyperparameter tuning 시도\n",
    "# 여기서는 scaling하지 않은 데이터로 한 번 training 해보려고 한다.\n",
    "# 그리고 test의 accuracy를 score_dict에 담아서 순위를 보려고 한다.\n",
    "\n",
    "scores = hyperparameter_tunning(kernel, gamma_list, C_list, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbf_1_0.1      0.966667\n",
       "rbf_0.8_0.1    0.966667\n",
       "rbf_0.9_0.1    0.966667\n",
       "rbf_0.5_1      0.933333\n",
       "rbf_0.8_1      0.933333\n",
       "rbf_0.9_1      0.933333\n",
       "rbf_1_1        0.933333\n",
       "rbf_0.6_0.1    0.933333\n",
       "rbf_2_0.01     0.933333\n",
       "rbf_2_0.1      0.933333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf 커널에서는 gamma가 1, C가 0.1일 때 test 결과 좋았다.\n",
    "# gamma가 클수록 overfitting, 작을수록 underfitting 되기 쉽다.\n",
    "# C가 클수록 오분류된 데이터를 줄이기 위한 것에 집중하여 overfitting되기 쉽다.\n",
    "\n",
    "pd.Series(scores).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:19<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "gamma_list = list(np.arange(0.5, 1.5, 0.02))\n",
    "C_list = list(np.arange(0.01, 0.5, 0.01))\n",
    "\n",
    "scores = hyperparameter_tunning(kernel, gamma_list, C_list, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbf_0.6400000000000001_0.29000000000000004     0.966667\n",
       "rbf_1.1600000000000006_0.01                    0.966667\n",
       "rbf_0.9200000000000004_0.15000000000000002     0.966667\n",
       "rbf_0.9200000000000004_0.14                    0.966667\n",
       "rbf_0.6200000000000001_0.37                    0.966667\n",
       "rbf_0.9200000000000004_0.13                    0.966667\n",
       "rbf_0.9200000000000004_0.12                    0.966667\n",
       "rbf_0.9200000000000004_0.09999999999999999     0.966667\n",
       "rbf_1.2800000000000007_0.12                    0.966667\n",
       "rbf_1.2800000000000007_0.11                    0.966667\n",
       "rbf_1.2800000000000007_0.09999999999999999     0.966667\n",
       "rbf_1.2800000000000007_0.09                    0.966667\n",
       "rbf_1.2800000000000007_0.08                    0.966667\n",
       "rbf_1.2800000000000007_0.06999999999999999     0.966667\n",
       "rbf_1.2800000000000007_0.060000000000000005    0.966667\n",
       "rbf_1.2800000000000007_0.05                    0.966667\n",
       "rbf_1.2800000000000007_0.04                    0.966667\n",
       "rbf_1.2800000000000007_0.03                    0.966667\n",
       "rbf_1.2800000000000007_0.02                    0.966667\n",
       "rbf_1.2800000000000007_0.01                    0.966667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더 세밀하게 hyperparameter를 움직여 보았지만 score가 더 오르지 않았다\n",
    "pd.Series(scores).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. scaling한 데이터로 학습\n",
    "standard_scaler = StandardScaler() \n",
    "X_scaled = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  6.86it/s]\n"
     ]
    }
   ],
   "source": [
    "kernel = 'rbf'\n",
    "C_list = [0.01, 0.1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 150, 200]\n",
    "gamma_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "scores = hyperparameter_tunning(kernel, gamma_list, C_list, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbf_0.8_1     0.966667\n",
       "rbf_0.5_1     0.966667\n",
       "rbf_0.7_1     0.966667\n",
       "rbf_0.6_1     0.966667\n",
       "rbf_0.8_2     0.933333\n",
       "rbf_0.7_50    0.933333\n",
       "rbf_0.6_70    0.933333\n",
       "rbf_1_2       0.933333\n",
       "rbf_0.9_2     0.933333\n",
       "rbf_2_3       0.933333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gamma가 0.8, C가 1일 때 accuracy가 높게 나와 이 근처에서 hyperparameter tuning을 더 해보려고 한다.\n",
    "pd.Series(scores).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "gamma_list = list(np.arange(0.5, 1.5, 0.02))\n",
    "C_list = list(np.arange(0.5, 3, 0.05))\n",
    "\n",
    "scores = hyperparameter_tunning(kernel, gamma_list, C_list, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbf_0.6400000000000001_0.9000000000000004    1.000000\n",
       "rbf_0.5800000000000001_0.8000000000000003    1.000000\n",
       "rbf_0.6000000000000001_0.8500000000000003    1.000000\n",
       "rbf_0.6000000000000001_0.9000000000000004    1.000000\n",
       "rbf_0.6000000000000001_0.9500000000000004    1.000000\n",
       "rbf_0.6600000000000001_0.9000000000000004    1.000000\n",
       "rbf_0.5800000000000001_0.8500000000000003    1.000000\n",
       "rbf_0.6000000000000001_0.8000000000000003    1.000000\n",
       "rbf_0.6200000000000001_0.9500000000000004    1.000000\n",
       "rbf_0.6200000000000001_0.9000000000000004    1.000000\n",
       "rbf_0.6200000000000001_0.8500000000000003    1.000000\n",
       "rbf_0.7400000000000002_0.8000000000000003    0.966667\n",
       "rbf_0.7400000000000002_0.7500000000000002    0.966667\n",
       "rbf_0.7200000000000002_1.2500000000000007    0.966667\n",
       "rbf_0.7400000000000002_0.7000000000000002    0.966667\n",
       "rbf_0.7400000000000002_0.6500000000000001    0.966667\n",
       "rbf_0.7400000000000002_0.6000000000000001    0.966667\n",
       "rbf_0.7200000000000002_1.3000000000000007    0.966667\n",
       "rbf_0.7400000000000002_0.9500000000000004    0.966667\n",
       "rbf_0.8400000000000003_0.6500000000000001    0.966667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더 세밀하게 hyperparameter를 움직여본 결과 test accuracy가 1이 나왔다 !!\n",
    "pd.Series(scores).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_setosa     = SVC(kernel ='rbf', gamma = 0.6, C = 0.9)\n",
    "svm_versicolor = SVC(kernel ='rbf', gamma = 0.6, C = 0.9)\n",
    "svm_virginica  = SVC(kernel ='rbf', gamma = 0.6, C = 0.9)\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\n",
    "\n",
    "# 각 클래스 별 모델을 학습시키기 위하여 target을 one-hot encoding 해준다.\n",
    "y_train_encoded = pd.get_dummies(y_train) \n",
    "\n",
    "# 각각의 model training\n",
    "svm_setosa.fit(X_train,y_train_encoded.iloc[:,0])\n",
    "svm_versicolor.fit(X_train,y_train_encoded.iloc[:,1])\n",
    "svm_virginica.fit(X_train,y_train_encoded.iloc[:,2])\n",
    "\n",
    "setosa_distance = svm_setosa.decision_function(X_test)\n",
    "versicolor_distance = svm_versicolor.decision_function(X_test)\n",
    "virginica_distance = svm_virginica.decision_function(X_test)\n",
    "\n",
    "# test 데이터 최종 예측\n",
    "pred = np.argmax(np.array([setosa_distance, versicolor_distance, virginica_distance]), axis=0)\n",
    "pred_eng = pd.Series(pred).replace({0:'setosa', 1:'versicolor', 2:'virginica'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 13,  1],\n",
       "       [ 0,  0, 15]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard scaling한 데이터 + rbf kernel + gamma 0.6 + C 0.9\n",
    "# test size = 0.3 으로 random_state 없이 한 번 더 예측\n",
    "# 역시 어느 정도 잘 나온다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_eng)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
